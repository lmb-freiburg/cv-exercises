{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a33e23",
   "metadata": {},
   "source": [
    "# Evaluate FlowNet and DispNet for disparity evaluation\n",
    "\n",
    "To evaluate the FlowNetS, FlowNetC, DispNetS and DispNetC for disparity evaluation on FlyingThings3D, we use the function eval() from the file eval.py. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b45aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import evaluate, setup_args\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.argv = [\"\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1139c3",
   "metadata": {},
   "source": [
    "## Evaluation command\n",
    "\n",
    "The following block will run the evaluation with the provided pre-trained weights on the FlyingThings3D test set. Note that the evaluation may run for several minutes. Have a look at the qualitative results by using tensorboard on the specified output directory.\n",
    "\n",
    "The function will try to load existing results instead of running the evaluation. To run the evaluations in the **command line instead of the notebook**, run:\n",
    "\n",
    "~~~bash\n",
    "python eval.py --model FlowNetS --auto_restore mw/flownets --output output/flownets\n",
    "python eval.py --model FlowNetC --auto_restore mw/flownetc --output output/flownetc\n",
    "python eval.py --model DispNetS --auto_restore mw/dispnets --output output/dispnets\n",
    "python eval.py --model DispNetC --auto_restore mw/dispnetc --output output/dispnetc\n",
    "~~~\n",
    "\n",
    "Then download the results and move them s.t. they are found by the `run_or_get_output` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03105d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"output\"\n",
    "\n",
    "\n",
    "def run_or_get_output(args):\n",
    "    output_dir = Path(args.output) / \"eval\" / \"FlyingThings3D\"\n",
    "    metrics_file = output_dir / \"metrics.csv\"\n",
    "    results_file = output_dir / \"results.csv\"\n",
    "    if metrics_file.is_file() and results_file.is_file():\n",
    "        print(f\"Loading results from {output_dir}\")\n",
    "        metrics = pd.read_csv(metrics_file, index_col=0)\n",
    "        # pandas save Series as DataFrame but we want to load it as Series again\n",
    "        results_df = pd.read_csv(results_file, index_col=0)\n",
    "        indx = results_df.index\n",
    "        vals = [results_df.iloc[i, 0] for i in range(len(indx))]\n",
    "        results = pd.Series(vals, index=indx)\n",
    "    else:\n",
    "        print(f\"Computing results with arguments {args}\")\n",
    "        metrics, results = evaluate(args)\n",
    "    return metrics, results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c840d",
   "metadata": {},
   "source": [
    "## FlowNetS Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf50db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = setup_args()\n",
    "args.model = \"FlowNetS\"\n",
    "args.auto_restore = \"mw/flownets\"\n",
    "args.output = f\"{OUTPUT_DIR}/flownets\"\n",
    "flownet_s_metrics, flownet_s_results = run_or_get_output(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860ef81d",
   "metadata": {},
   "source": [
    "The metrics for each sample and the averaged results are returned as pandas Seris and Dataframes, which can be directly displayed by Jupyter notebook as tables and be easily plotted with matplotlib. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4154fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "flownet_s_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c74a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flownet_s_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4d72a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flownet_s_metrics.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa84b1a",
   "metadata": {},
   "source": [
    "## FlowNetC Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74007a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = setup_args()\n",
    "args.model = \"FlowNetC\"\n",
    "args.auto_restore = \"mw/flownetc\"\n",
    "args.output = f\"{OUTPUT_DIR}/flownetc\"\n",
    "flownet_c_metrics, flownet_c_results = run_or_get_output(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32acbaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flownet_c_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90196812",
   "metadata": {},
   "source": [
    "## DispNetS Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b10a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = setup_args()\n",
    "args.model = \"DispNetS\"\n",
    "args.auto_restore = \"mw/dispnets\"\n",
    "args.output = f\"{OUTPUT_DIR}/dispnets\"\n",
    "dispnet_s_metrics, dispnet_s_results = run_or_get_output(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5478d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dispnet_s_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a6aaa5",
   "metadata": {},
   "source": [
    "## DispNetC Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4efc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = setup_args()\n",
    "args.model = \"DispNetC\"\n",
    "args.auto_restore = \"mw/dispnetc\"\n",
    "args.output = f\"{OUTPUT_DIR}/dispnetc\"\n",
    "dispnet_c_metrics, dispnet_c_results = run_or_get_output(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40a5118",
   "metadata": {},
   "source": [
    "If your correlation layer implementation from the previous task was correct, this should give an EPE of 1.67."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96324ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dispnet_c_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f7352",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "\n",
    "Now that results are available for all four models, we want to compare results. Your task is to show the results as table and plot them as shown on the assignment sheet.\n",
    "For this, you have to combine the pandas Series/DataFrames that contain the metrics/results of each model. Have a look at the pandas documentation and make use of the notebook to quickly try and check commands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5473955",
   "metadata": {},
   "outputs": [],
   "source": [
    "flownet_s_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eea5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"FlowNetS\": flownet_s_results,\n",
    "    \"FlowNetC\": flownet_c_results,\n",
    "    \"DispNetS\": dispnet_s_results,\n",
    "    \"DispNetC\": dispnet_c_results,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6716cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START TODO #################\n",
    "# Combine the flownet_s_metrics, flownet_c_metrics, dispnet_s_metrics and dispnet_c_metrics\n",
    "# to a pandas DataFrame called combined_metrics.\n",
    "# Combine the flownet_s_results, flownet_c_results, dispnet_s_results and dispnet_c_results\n",
    "# to a pandas DataFrame called combined_results.\n",
    "# combined_metrics = ...\n",
    "# combined_results = ...\n",
    "raise NotImplementedError\n",
    "# END TODO #################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b59e0a",
   "metadata": {},
   "source": [
    "Show the combined metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ffaf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4512fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_metrics.plot(ylabel=\"EPE\", ylim=(0, 30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "face0dc6",
   "metadata": {},
   "source": [
    "Show the combined results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84d07cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97461822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START TODO #################\n",
    "# Create the bar plot as shown in Figure 3b of the assignment sheet.\n",
    "raise NotImplementedError\n",
    "# END TODO #################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070f9cc2",
   "metadata": {},
   "source": [
    "## Rectification\n",
    "\n",
    "See the assignment PDF for details, chapter *Apply DispNet to images from a monocular camera*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff2a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from importlib import reload\n",
    "from PIL import Image\n",
    "from lib.vis import np2d, np3d\n",
    "import lib.utils as utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b2e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    path_l = osp.join(path, \"left.png\")\n",
    "    path_r = osp.join(path, \"right.png\")\n",
    "\n",
    "    image_l = np.array(Image.open(path_l)).transpose([2, 0, 1])  # 3, H, W\n",
    "    image_r = np.array(Image.open(path_r)).transpose([2, 0, 1])  # 3, H, W\n",
    "    _, h_orig, w_orig = image_l.shape\n",
    "\n",
    "    K = np.load(osp.join(path, \"K.npy\"))\n",
    "    r_to_l_transform = np.load(osp.join(path, \"right_to_left_transform.npy\"))\n",
    "    return image_l, image_r, K, r_to_l_transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787bad58",
   "metadata": {},
   "source": [
    "First we implement some basic functions for:\n",
    "- projecting a 3d point to an image\n",
    "- computing the epipole from another camera in a current image\n",
    "- computing the essential and fundamental matrices\n",
    "\n",
    "We will test these functions on multiple samples from different datasets in the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def0c97c",
   "metadata": {},
   "source": [
    "### KITTI 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db15c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/kitti\"\n",
    "image_l, image_r, K, r_to_l_transform = load_data(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdad2cbc",
   "metadata": {},
   "source": [
    "First we simply visualize the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be7e0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np3d(np.concatenate([image_l, image_r], -1), image_range_text_off=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f9605d",
   "metadata": {},
   "source": [
    "Note that the images are actually not left and right images from a stereo camera pair! Instead the images are from a video with forward motion between the first and second image. We still call the first image image_l and the second image image_r, as this is how the DispNet will interpret the images.\n",
    "\n",
    "Next we compute the epipoles in both images and visualize them in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7763b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "epi_in_r = utils.get_epipole(K, r_to_l_transform)\n",
    "epi_in_l = utils.get_epipole(K, utils.invert_transform(r_to_l_transform))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e17860",
   "metadata": {},
   "outputs": [],
   "source": [
    "np3d(\n",
    "    image_l,\n",
    "    markers=[{\"xy_pos\": epi_in_l, \"desc\": \"epipole\"}],\n",
    "    text=\"Image 1 with epipole from image 2\",\n",
    "    image_range_text_off=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743295f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np3d(\n",
    "    image_r,\n",
    "    markers=[{\"xy_pos\": epi_in_r, \"desc\": \"epipole\"}],\n",
    "    text=\"Image 2 with epipole from image 1\",\n",
    "    image_range_text_off=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f773dd",
   "metadata": {},
   "source": [
    "Note that the epipole from image 1 is within the image plane of image 2 even though the camera from image 2 is *behind* the image plane of image 1. This simply is because mathematically also points behind the image plane can be projected onto the image plane and we did not check this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb0b940",
   "metadata": {},
   "source": [
    "Next we can visualize some epipolar lines in the second image. For this, we need to compute the fundamental matrix from the known camera calibration. We call the fundamental matrix F_l_to_r, as it gives us an epipolar line l=Fx in the right (=second) image given a point x in the left (=first) image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1356a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "F_l_to_r = utils.compute_fundamental_matrix(K, r_to_l_transform)\n",
    "F_l_to_r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20760ce3",
   "metadata": {},
   "source": [
    "It is also possible to compute the fundamental matrix from the essential matrix. Here, we use this as a sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d7659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "E_l_to_r = utils.compute_essential_matrix(r_to_l_transform)\n",
    "F_l_to_r_check = np.linalg.inv(K.T).dot(E_l_to_r).dot(np.linalg.inv(K))\n",
    "F_l_to_r_check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead6a9ca",
   "metadata": {},
   "source": [
    "On first glance the fundamental matrix that was computed from the essential matrix looks different. But keep in mind that the fundamental matrix is defined only up to scale, so it is okay if both matrices differ by a fixed scale factor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8106e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_l_to_r_check / F_l_to_r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac93371",
   "metadata": {},
   "source": [
    "We can now use the fundamental matrix to visualize epipolar lines in the second image for reference points in the first image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef48c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "x_ref_0 = (96, 130)\n",
    "x_ref_1 = (290, 300)\n",
    "color_0 = (0, 255, 0)\n",
    "color_1 = (0, 0, 255)\n",
    "image_r_epilines = utils.plot_epipolar_line(\n",
    "    image_r, F_l_to_r, x_ref=x_ref_0, line_color=color_0\n",
    ")\n",
    "image_r_epilines = utils.plot_epipolar_line(\n",
    "    image_r_epilines, F_l_to_r, x_ref=x_ref_1, line_color=color_1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db32e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "np3d(\n",
    "    image_l,\n",
    "    markers=[\n",
    "        {\"xy_pos\": epi_in_l, \"desc\": \"epipole\"},\n",
    "        {\"xy_pos\": x_ref_0, \"desc\": \"x_ref_0\", \"marker_color\": color_0},\n",
    "        {\"xy_pos\": x_ref_1, \"desc\": \"x_ref_1\", \"marker_color\": color_1},\n",
    "    ],\n",
    "    text=\"Image 1 with epipole from image 2\",\n",
    "    image_range_text_off=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac58003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np3d(\n",
    "    image_r_epilines,\n",
    "    markers=[{\"xy_pos\": epi_in_r, \"desc\": \"epipole\"}],\n",
    "    text=\"Image 2 with epipole from image 1 and epipolar lines for two reference points\",\n",
    "    image_range_text_off=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462155a4",
   "metadata": {},
   "source": [
    "You can visualize check that the epipolar lines cross the corresponding points of the two referents points in the first image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae93ddc1",
   "metadata": {},
   "source": [
    "### KITTI 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d76e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/kitti_2\"\n",
    "image_l, image_r, K, r_to_l_transform = load_data(path)\n",
    "np3d(np.concatenate([image_l, image_r], -1), image_range_text_off=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6e1d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_in_r = utils.get_epipole(K, r_to_l_transform)\n",
    "epi_in_l = utils.get_epipole(K, utils.invert_transform(r_to_l_transform))\n",
    "F_l_to_r = utils.compute_fundamental_matrix(K, r_to_l_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a313401",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "x_ref_0 = (310, 230)\n",
    "x_ref_1 = (480, 240)\n",
    "color_0 = (0, 255, 0)\n",
    "color_1 = (0, 0, 255)\n",
    "image_r_epilines = utils.plot_epipolar_line(\n",
    "    image_r, F_l_to_r, x_ref=x_ref_0, line_color=color_0\n",
    ")\n",
    "image_r_epilines = utils.plot_epipolar_line(\n",
    "    image_r_epilines, F_l_to_r, x_ref=x_ref_1, line_color=color_1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42eaf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "np3d(\n",
    "    image_l,\n",
    "    markers=[\n",
    "        {\"xy_pos\": epi_in_l, \"desc\": \"epipole\"},\n",
    "        {\"xy_pos\": x_ref_0, \"desc\": \"x_ref_0\", \"marker_color\": color_0},\n",
    "        {\"xy_pos\": x_ref_1, \"desc\": \"x_ref_1\", \"marker_color\": color_1},\n",
    "    ],\n",
    "    text=\"Image 1 with epipole from image 2\",\n",
    "    image_range_text_off=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd590e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np3d(\n",
    "    image_r_epilines,\n",
    "    markers=[{\"xy_pos\": epi_in_r, \"desc\": \"epipole\"}],\n",
    "    text=\"Image 2 with epipole from image 1 and epipolar lines for two reference points\",\n",
    "    image_range_text_off=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa9c98",
   "metadata": {},
   "source": [
    "### RealThings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b077344",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/realthings\"\n",
    "image_l, image_r, K, r_to_l_transform = load_data(path)\n",
    "np3d(np.concatenate([image_l, image_r], -1), image_range_text_off=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968f1b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_in_r = utils.get_epipole(K, r_to_l_transform)\n",
    "epi_in_l = utils.get_epipole(K, utils.invert_transform(r_to_l_transform))\n",
    "F_l_to_r = utils.compute_fundamental_matrix(K, r_to_l_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e6f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "x_ref_0 = (480, 200)\n",
    "x_ref_1 = (690, 370)\n",
    "color_0 = (0, 255, 0)\n",
    "color_1 = (0, 0, 255)\n",
    "image_r_epilines = utils.plot_epipolar_line(\n",
    "    image_r, F_l_to_r, x_ref=x_ref_0, line_color=color_0\n",
    ")\n",
    "image_r_epilines = utils.plot_epipolar_line(\n",
    "    image_r_epilines, F_l_to_r, x_ref=x_ref_1, line_color=color_1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9c2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "np3d(\n",
    "    image_l,\n",
    "    markers=[\n",
    "        {\"xy_pos\": epi_in_l, \"desc\": \"epipole\"},\n",
    "        {\"xy_pos\": x_ref_0, \"desc\": \"x_ref_0\", \"marker_color\": color_0},\n",
    "        {\"xy_pos\": x_ref_1, \"desc\": \"x_ref_1\", \"marker_color\": color_1},\n",
    "    ],\n",
    "    text=\"Image 1\",\n",
    "    image_range_text_off=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7402786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np3d(\n",
    "    image_r_epilines,\n",
    "    markers=[{\"xy_pos\": epi_in_r, \"desc\": \"epipole\"}],\n",
    "    text=\"Image 2 with epipolar lines for two reference points\",\n",
    "    image_range_text_off=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed2cbd5",
   "metadata": {},
   "source": [
    "Note that for this image pair the epipoles are out of the image boundaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217e687",
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_in_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25399920",
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_in_r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a136ce5",
   "metadata": {},
   "source": [
    "### Rectification\n",
    "\n",
    "We will work with the RealThings image pair for the following rectification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d567db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "image_l_rect, image_r_rect, H_l, H_r, rrect_to_lrect_transform = utils.rectify_images(\n",
    "    image_l, image_r, K, r_to_l_transform\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507499b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np3d(np.concatenate([image_l_rect, image_r_rect], -1), image_range_text_off=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa01dc08",
   "metadata": {},
   "source": [
    "Next we can verify that epipolar lines are horizontal by visualizing the epipolar lines for the same reference points as before. Note that the reference point coordinates also changed, as the left image was warped too:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3d5216",
   "metadata": {},
   "source": [
    "We can check that after rectification the epipoles are at infinity (i.e. (f, 0, 0) in homogeneous coordinates) and the fundamental matrix is of the form i_x where i=(1, 0, 0) and the i_x is the corresponding skew-symmetric matrix that represents a cross product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f71a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_in_r = utils.get_epipole(K, rrect_to_lrect_transform, return_hom=True)\n",
    "epi_in_l = utils.get_epipole(\n",
    "    K, utils.invert_transform(rrect_to_lrect_transform), return_hom=True\n",
    ")\n",
    "F_lrect_to_rrect = utils.compute_fundamental_matrix(K, rrect_to_lrect_transform)\n",
    "\n",
    "print(\"Epipole in left image: {}.\".format(epi_in_l))\n",
    "print(\"Epipole in right image: {}.\".format(epi_in_r))\n",
    "print(\"Fundamental matrix: \\n{}.\".format(F_lrect_to_rrect / F_lrect_to_rrect[1, 2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630dbc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ref_0_rect = H_l.dot(np.append(np.array(x_ref_0), 1))\n",
    "x_ref_0_rect = np.array(\n",
    "    [x_ref_0_rect[0] / x_ref_0_rect[2], x_ref_0_rect[1] / x_ref_0_rect[2]]\n",
    ")\n",
    "x_ref_1_rect = H_l.dot(np.append(np.array(x_ref_1), 1))\n",
    "x_ref_1_rect = np.array(\n",
    "    [x_ref_1_rect[0] / x_ref_1_rect[2], x_ref_1_rect[1] / x_ref_1_rect[2]]\n",
    ")\n",
    "print(\n",
    "    \"Reference point 0 was at {} and is at {} after rectification.\".format(\n",
    "        x_ref_0, x_ref_0_rect\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Reference point 1 was at {} and is at {} after rectification.\".format(\n",
    "        x_ref_1, x_ref_1_rect\n",
    "    )\n",
    ")\n",
    "\n",
    "image_r_rect_epilines = utils.plot_epipolar_line(\n",
    "    image_r_rect, F_lrect_to_rrect, x_ref=x_ref_0_rect, line_color=color_0\n",
    ")\n",
    "image_r_rect_epilines = utils.plot_epipolar_line(\n",
    "    image_r_rect_epilines, F_lrect_to_rrect, x_ref=x_ref_1_rect, line_color=color_1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34db770",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np3d(\n",
    "    image_l_rect,\n",
    "    markers=[\n",
    "        {\"xy_pos\": x_ref_0_rect, \"desc\": \"x_ref_0\", \"marker_color\": color_0},\n",
    "        {\"xy_pos\": x_ref_1_rect, \"desc\": \"x_ref_1\", \"marker_color\": color_1},\n",
    "    ],\n",
    "    text=\"Image 1\",\n",
    "    image_range_text_off=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bd0bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np3d(\n",
    "    image_r_rect_epilines,\n",
    "    text=\"Image 2 with epipolar lines for two reference points\",\n",
    "    image_range_text_off=True,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}